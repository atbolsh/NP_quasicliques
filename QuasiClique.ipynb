{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we have an edge matrix $G$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 1],\n",
       "       [1, 1, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from projections import *\n",
    "from graphReader import *\n",
    "from helpers import *\n",
    "\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can convert that to an \"error matrix\" of all elements that are NOT connected, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 1., 0., 0., 1.],\n",
       "       [1., 0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are looking for a clique. That is hard. However, we can start by looking for a quasi-clique, or a set of orthonormal vectors $X$ that satisfies $X^T M X = 0$.\n",
    "\n",
    "How can we do this?\n",
    "\n",
    "Well, assume we already have a set of vectors $X$ which we are trying to expand. Lets have a couple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Xs\n",
      "[[ 0.6         0.30769231]\n",
      " [ 0.8        -0.23076923]\n",
      " [ 0.          0.92307692]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.47058824 -0.88235294]\n",
      " [ 0.88235294  0.47058824]\n",
      " [ 0.          0.        ]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "\n",
      "\n",
      "Orthonormality Check - should be Id\n",
      "[[ 1. -0.]\n",
      " [-0.  1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "\n",
      "\n",
      "condition Check - should be 0\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "X  = np.array([[3.0/5, 4.0/5, 0, 0, 0], [(4.0/13), (-3.0/13), 12.0/13, 0, 0]]).T\n",
    "X2 = np.array([[0, 0, 8.0/17, 15.0/17, 0], [0, 0, -15.0/17, 8.0/17, 0]]).T\n",
    "X3 = np.array([[0, 0, 0, 0, 1.0]]).T\n",
    "\n",
    "print(\"\\n\\nXs\")\n",
    "print(X)\n",
    "print(X2)\n",
    "print(X3)\n",
    "\n",
    "print(\"\\n\\nOrthonormality Check - should be Id\")\n",
    "print(np.matmul(X.T, X).round(3))\n",
    "print(np.matmul(X2.T, X2).round(3))\n",
    "print(np.matmul(X3.T, X3).round(3))\n",
    "\n",
    "def convolve(basis, Matrix):\n",
    "    return np.matmul(basis.T, np.matmul(Matrix, basis))\n",
    "\n",
    "print(\"\\n\\ncondition Check - should be 0\")\n",
    "print(convolve(X, M))\n",
    "print(convolve(X2, M))\n",
    "print(convolve(X3, M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we are now looking for a vector $x$ which is orthogonal to $X$, to $MX$ and which satisfies $x^T M x = 0$.\n",
    "\n",
    "We can work through these requirements one at at time. The projection onto the space spanned by $X$ is easy to write - it's just $XX^T$ - so the projection onto the kernel of that span is just $Id - XX^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.545 -0.409 -0.284  0.     0.   ]\n",
      " [-0.409  0.307  0.213  0.     0.   ]\n",
      " [-0.284  0.213  0.148  0.     0.   ]\n",
      " [ 0.     0.     0.     1.     0.   ]\n",
      " [ 0.     0.     0.     0.     1.   ]]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "kerX  = np.eye(5) - np.matmul(X, X.T)\n",
    "kerX2 = np.eye(5) - np.matmul(X2, X2.T)\n",
    "kerX3 = np.eye(5) - np.matmul(X3, X3.T)\n",
    "print(kerX.round(3))\n",
    "print(kerX2.round(3))\n",
    "print(kerX3.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to deal with $MX$, which is a little harder since it's not *ab initio* orthonormal.\n",
    "\n",
    "Let's first look at $S = MX$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.   ]\n",
      " [0.    0.   ]\n",
      " [0.    0.   ]\n",
      " [1.4   0.077]\n",
      " [0.6   1.231]]\n",
      "[[ 0.882  0.471]\n",
      " [ 0.882  0.471]\n",
      " [ 0.     0.   ]\n",
      " [ 0.     0.   ]\n",
      " [ 1.353 -0.412]]\n",
      "[[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "S = np.matmul(M, X)\n",
    "S2 = np.matmul(M, X2)\n",
    "S3 = np.matmul(M, X3)\n",
    "print(S.round(3))\n",
    "print(S2.round(3))\n",
    "print(S3.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, clearly $S$ has two linearly independent components, but it is not orthonormal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.32       0.84615385]\n",
      " [0.84615385 1.52071006]]\n",
      "[[3.38754325 0.2733564 ]\n",
      " [0.2733564  0.61245675]]\n",
      "[[3.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.matmul(S.T, S))\n",
    "print(np.matmul(S2.T, S2))\n",
    "print(np.matmul(S3.T, S3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still, however, a simple enough procedure to obtain a projection onto the span of $S$. Start with the basic matrix $S S^T$, then use svd to compute $T v D = S S^T$. Set the nonzero elements of $v$ to 1, and compute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.85613942 0.98457063 0.         0.         0.        ]\n",
      "[3.414 0.586 0.    0.    0.   ]\n",
      "[3. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "P  = np.matmul(S, S.T)\n",
    "P2 = np.matmul(S2, S2.T)\n",
    "P3 = np.matmul(S3, S3.T)\n",
    "\n",
    "T,  v,  D  = np.linalg.svd(P)\n",
    "T2, v2, D2 = np.linalg.svd(P2)\n",
    "T3, v3, D3 = np.linalg.svd(P3)\n",
    "print(v)\n",
    "print(v2.round(3))\n",
    "print(v3.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 0.]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -0.]\n",
      " [ 0.  0.  0.  0.  1.]]\n",
      "[[ 0.5  0.5  0.   0.   0. ]\n",
      " [ 0.5  0.5  0.   0.  -0. ]\n",
      " [ 0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0. ]\n",
      " [ 0.  -0.   0.   0.   1. ]]\n",
      "[[0.333 0.    0.333 0.333 0.   ]\n",
      " [0.    0.    0.    0.    0.   ]\n",
      " [0.333 0.    0.333 0.333 0.   ]\n",
      " [0.333 0.    0.333 0.333 0.   ]\n",
      " [0.    0.    0.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-7\n",
    "w  = np.array([float(el > eps) for el in v])\n",
    "w2 = np.array([float(el > eps) for el in v2])\n",
    "w3 = np.array([float(el > eps) for el in v3])\n",
    "\n",
    "# They're all the same\n",
    "print(w)\n",
    "\n",
    "Q  = np.matmul(T,  np.matmul(w*np.eye(5),  D))\n",
    "Q2 = np.matmul(T2, np.matmul(w2*np.eye(5), D2))\n",
    "Q3 = np.matmul(T3, np.matmul(w3*np.eye(5), D3))\n",
    "\n",
    "print(Q.round(3))\n",
    "print(Q2.round(3))\n",
    "print(Q3.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is $Q$ really a projection matrix? Well, it would appear so, since $Q^2 = Q$ in all cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -0.]\n",
      " [ 0.  0.  0.  0.  1.]]\n",
      "[[ 0.5  0.5  0.   0.   0. ]\n",
      " [ 0.5  0.5  0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0. ]\n",
      " [-0.  -0.   0.   0.   1. ]]\n",
      "[[0.333 0.    0.333 0.333 0.   ]\n",
      " [0.    0.    0.    0.    0.   ]\n",
      " [0.333 0.    0.333 0.333 0.   ]\n",
      " [0.333 0.    0.333 0.333 0.   ]\n",
      " [0.    0.    0.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.matmul(Q,  Q).round(3))\n",
    "print(np.matmul(Q2, Q2).round(3))\n",
    "print(np.matmul(Q3, Q3).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the projection onto the kernel of the span of $MX$ is just $Id - Q$, so the projection onto the kernel of both $X$ and $MX$ is going to be\n",
    "$$K = (Id - XX^T)(Id - Q)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.545 -0.409 -0.284  0.     0.   ]\n",
      " [-0.409  0.307  0.213  0.     0.   ]\n",
      " [-0.284  0.213  0.148  0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]\n",
      " [ 0.     0.     0.    -0.     0.   ]]\n",
      "[[ 0.5 -0.5  0.   0.  -0. ]\n",
      " [-0.5  0.5  0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0. ]]\n",
      "[[ 0.667  0.    -0.333 -0.333  0.   ]\n",
      " [ 0.     1.     0.     0.     0.   ]\n",
      " [-0.333  0.     0.667 -0.333  0.   ]\n",
      " [-0.333  0.    -0.333  0.667  0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n"
     ]
    }
   ],
   "source": [
    "kerMX = np.eye(5) - Q\n",
    "kernel = np.matmul(kerX, kerMX)\n",
    "\n",
    "kerMX2 = np.eye(5) - Q2\n",
    "kernel2 = np.matmul(kerX2, kerMX2)\n",
    "\n",
    "kerMX3 = np.eye(5) - Q3\n",
    "kernel3 = np.matmul(kerX3, kerMX3)\n",
    "\n",
    "print(kernel.round(3))\n",
    "print(kernel2.round(3))\n",
    "print(kernel3.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, now all that is left is to find the space that $K$ spans, and look at the action of $M$ on this space only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0.]\n",
      "[[-0.73846154  0.55384615  0.38461538  0.          0.        ]\n",
      " [-0.          0.          0.         -0.90955199 -0.41559015]\n",
      " [-0.05450082 -0.61755479  0.78463733  0.          0.        ]\n",
      " [ 0.          0.          0.         -0.41559015  0.90955199]\n",
      " [-0.67208944 -0.55846264 -0.48622553 -0.         -0.        ]]\n",
      "\n",
      "\n",
      "Basis vector(s) of each new space\n",
      "[[-0.738]\n",
      " [ 0.554]\n",
      " [ 0.385]\n",
      " [ 0.   ]\n",
      " [ 0.   ]]\n",
      "[[-0.707]\n",
      " [ 0.707]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]]\n",
      "[[ 0.     0.816  0.   ]\n",
      " [-1.     0.     0.   ]\n",
      " [-0.    -0.408 -0.707]\n",
      " [ 0.    -0.408  0.707]\n",
      " [ 0.     0.     0.   ]]\n",
      "\n",
      "\n",
      "Action of M on each subspace:\n",
      "[[0.]]\n",
      "[[-0.]]\n",
      "[[ 0.     0.408 -0.707]\n",
      " [ 0.408 -0.667  0.577]\n",
      " [-0.707  0.577  0.   ]]\n"
     ]
    }
   ],
   "source": [
    "Bt,  u,  B  = np.linalg.svd(kernel)\n",
    "B2t, u2, B2 = np.linalg.svd(kernel2)\n",
    "B3t, u3, B3 = np.linalg.svd(kernel3)\n",
    "\n",
    "# THey're all the same\n",
    "print(u.round(3))\n",
    "print(B)\n",
    "\n",
    "ind  = [i for i in range(5) if u[i] > eps]\n",
    "ind2 = [i for i in range(5) if u2[i] > eps]\n",
    "ind3 = [i for i in range(5) if u3[i] > eps]\n",
    "\n",
    "# This is the parametrization of the space we care about:\n",
    "b = B[ind, :].T\n",
    "b2 = B2[ind2, :].T\n",
    "b3 = B3[ind3, :].T\n",
    "\n",
    "print(\"\\n\\nBasis vector(s) of each new space\")\n",
    "print(b.round(3))\n",
    "print(b2.round(3))\n",
    "print(b3.round(3))\n",
    "\n",
    "# This is the action of M on only the space we care about:\n",
    "print(\"\\n\\nAction of M on each subspace:\")\n",
    "M1 = np.matmul(b.T,  np.matmul(M, b))\n",
    "M2 = np.matmul(b2.T, np.matmul(M, b2))\n",
    "M3 = np.matmul(b3.T, np.matmul(M, b3))\n",
    "\n",
    "print(M1.round(3))\n",
    "print(M2.round(3))\n",
    "print(M3.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the action of $M$ restricted to the subspace in question, all that's left is to use the \"nullproject\" function from projections (not discussed here, but simple enough to derive) to find vectors in each subspace which satisfy $x^TMx = 0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "[-1.]\n",
      "[-0.26854502 -0.32889914  0.90537778]\n"
     ]
    }
   ],
   "source": [
    "v1 = np.random.random(M1.shape[0])*2 - 1\n",
    "v2 = np.random.random(M2.shape[0])*2 - 1\n",
    "v3 = np.random.random(M3.shape[0])*2 - 1\n",
    "\n",
    "v1 = v1/norm(v1)\n",
    "v2 = v2/norm(v2)\n",
    "v3 = v3/norm(v3)\n",
    "\n",
    "u1 = nullproject(M1, v1)\n",
    "u2 = nullproject(M2, v2)\n",
    "u3 = nullproject(M3, v3)\n",
    "\n",
    "print(u1)\n",
    "print(u2)\n",
    "print(u3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can express these vectors in the original basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "New vectors x:\n",
      "[[-0.738]\n",
      " [ 0.554]\n",
      " [ 0.385]\n",
      " [ 0.   ]\n",
      " [ 0.   ]]\n",
      "[[ 0.707]\n",
      " [-0.707]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [-0.   ]]\n",
      "[[-0.269]\n",
      " [ 0.269]\n",
      " [-0.506]\n",
      " [ 0.774]\n",
      " [ 0.   ]]\n",
      "\n",
      "\n",
      "Testing property:\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.matmul(b, u1).reshape(5, 1)\n",
    "x2 = np.matmul(b2, u2).reshape(5, 1)\n",
    "x3 = np.matmul(b3, u3).reshape(5, 1)\n",
    "\n",
    "print(\"\\n\\nNew vectors x:\")\n",
    "print(x1.round(3))\n",
    "print(x2.round(3))\n",
    "print(x3.round(3))\n",
    "\n",
    "print(\"\\n\\nTesting property:\")\n",
    "print(np.matmul(x3.T, np.matmul(M, x3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that's really left is to add this to the old list of vectors, and we're done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6    0.308 -0.738]\n",
      " [ 0.8   -0.231  0.554]\n",
      " [ 0.     0.923  0.385]\n",
      " [ 0.     0.     0.   ]\n",
      " [ 0.     0.     0.   ]]\n",
      "[[ 0.     0.     0.707]\n",
      " [ 0.     0.    -0.707]\n",
      " [ 0.471 -0.882  0.   ]\n",
      " [ 0.882  0.471  0.   ]\n",
      " [ 0.     0.    -0.   ]]\n",
      "[[ 0.    -0.269]\n",
      " [ 0.     0.269]\n",
      " [ 0.    -0.506]\n",
      " [ 0.     0.774]\n",
      " [ 1.     0.   ]]\n"
     ]
    }
   ],
   "source": [
    "Y  = np.concatenate((X, x1), axis=1)\n",
    "Y2 = np.concatenate((X2, x2), axis=1)\n",
    "Y3 = np.concatenate((X3, x3), axis=1)\n",
    "\n",
    "print(Y.round(3))\n",
    "print(Y2.round(3))\n",
    "print(Y3.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What now? It's not clear. It's worth playing with this stuff, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0. -0.  0.  0.]\n",
      " [ 0.  1. -0.  0.  0.]\n",
      " [-0. -0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n",
      "[[ 0.5 -0.5  0.   0.  -0. ]\n",
      " [-0.5  0.5  0.   0.   0. ]\n",
      " [ 0.   0.   1.  -0.   0. ]\n",
      " [ 0.   0.  -0.   1.   0. ]\n",
      " [-0.   0.   0.   0.   0. ]]\n",
      "[[-0.    -0.    -0.999  0.036  0.   ]\n",
      " [-0.707  0.707  0.     0.     0.   ]\n",
      " [ 0.     0.     0.036  0.999  0.   ]\n",
      " [ 0.707  0.707  0.     0.    -0.   ]\n",
      " [-0.    -0.     0.     0.    -1.   ]]\n",
      "[[ 0.    -0.     0.     0.051  0.963]\n",
      " [-0.    -0.     0.     0.     0.707]\n",
      " [ 0.     0.     0.     1.413 -1.036]\n",
      " [ 0.051  0.     1.413 -0.    -0.707]\n",
      " [ 0.963  0.707 -1.036 -0.707  0.   ]]\n",
      "[[0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 1.]\n",
      " [1. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 0.]]\n",
      "[[0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 1. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 0.]]\n",
      "[[0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 1.]\n",
      " [1. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 0.]]\n",
      "[[ 0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1. -1.]\n",
      " [ 1.  0.  1.  0. -1.]\n",
      " [ 1.  1. -1. -1.  0.]]\n",
      "[[ True  True  True  True  True]\n",
      " [ True  True  True False False]\n",
      " [ True  True  True False  True]\n",
      " [ True False False  True  True]\n",
      " [ True False  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(np.matmul(Y, Y.T).round(3))\n",
    "print(np.matmul(Y2, Y2.T).round(3))\n",
    "\n",
    "D, k, C = svd(np.matmul(Y2, Y2.T))\n",
    "print(C.round(3))\n",
    "# It really looks like novel has more than one prominent hole in the rest of the structure:\n",
    "novel = np.matmul(C, np.matmul(M, C.T))\n",
    "print(novel.round(3))\n",
    "connections = np.sign(abs(novel.round(6)))\n",
    "\n",
    "print(np.sign(abs(novel.round(6))))\n",
    "corr = np.eye(5)\n",
    "corr[0, 1] = 1\n",
    "corr[1, 0] = 1\n",
    "corr[0, 0] = 0\n",
    "corr[1, 1] = 0\n",
    "tester = np.matmul(corr, np.matmul(M, corr))\n",
    "# print(M)\n",
    "# print(corr)\n",
    "print(M)\n",
    "print(connections)\n",
    "print(np.sign(novel.round(6)))\n",
    "print(M == np.sign(abs(novel.round(6))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With any luck, that sort of transformation will be sufficient. No idea how to guarantee the non-computed rows behave so nicely, though. We'll have to see until after I code up the \"get a quasi-clique\" formula. Maybe there's a good gradient-descent algorithm that takes one from a quasi-clique to a clique without violating any properties.\n",
    "\n",
    "The golden goose would be getting \"corr\" from the matrix Y2. I wonder if that is possible.\n",
    "\n",
    "Meanwhile, some exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1.  0.  0.  0.]\n",
      " [-1. -0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -0.  0.]\n",
      " [ 0.  0. -0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "a, b, c = svd(corr)\n",
    "#print(b)\n",
    "#print(c)\n",
    "#print(a)\n",
    "print(np.matmul(D, C).round(3))\n",
    "#print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(sum(M)))\n",
    "print(sum(sum(connections)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
